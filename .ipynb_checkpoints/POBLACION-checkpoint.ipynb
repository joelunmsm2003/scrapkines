{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('world.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Country', u'Region', u'Population', u'Area (sq. mi.)',\n",
      "       u'Pop. Density (per sq. mi.)', u'Coastline (coast/area ratio)',\n",
      "       u'Net migration', u'Infant mortality (per 1000 births)',\n",
      "       u'GDP ($ per capita)', u'Literacy (%)', u'Phones (per 1000)',\n",
      "       u'Arable (%)', u'Crops (%)', u'Other (%)', u'Climate', u'Birthrate',\n",
      "       u'Deathrate', u'Agriculture', u'Industry', u'Service'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist =tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.2668 - acc: 0.9215\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 6s 105us/step - loss: 0.1077 - acc: 0.9669\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 7s 114us/step - loss: 0.0728 - acc: 0.9775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2c18c54d10>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
    "x_train=tf.keras.utils.normalize(x_train,axis=1)\n",
    "x_test=tf.keras.utils.normalize(x_test,axis=1)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(10,activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(x_train,y_train,epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADltJREFUeJzt3W+MVfWdx/HPF5hBHRoBGSb8GRiWmFWCWag3IwGzYVNpLGnEPjElpmETU2pSk5L0wRr7oDw0zbaNiZsqXUnRdKWbtEYSyW6VNCFNVmQ0KFosIAwyODJDBv/wJ1aH7z6YQzPqnN8Z779zh+/7lUzm3vM9555vDnzm3Ht/956fubsAxDOt7AYAlIPwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IakYzdzZv3jzv6elp5i6BUPr7+3Xu3DmbzLo1hd/M7pb0mKTpkv7T3R9Nrd/T06O+vr5adgkgoVKpTHrdqp/2m9l0Sf8h6VuSVkjabGYrqn08AM1Vy2v+XknH3f2Eu/9N0m5Jm+rTFoBGqyX8iySdHnd/IFv2OWa21cz6zKxveHi4ht0BqKeGv9vv7jvcveLulc7OzkbvDsAk1RL+M5K6x91fnC0DMAXUEv6Dkm42s2Vm1i7pu5L21KctAI1W9VCfu39mZg9J+l+NDfXtdPe36tYZgIaqaZzf3fdK2lunXgA0ER/vBYIi/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+IKiaZuk1s35JH0salfSZu1fq0RTqx92T9U8//bSm7YscOXKk6m1PnTqVrK9fvz5Z3759e27twIEDyW3Pnz+frPf39yfrly9fTtZbQU3hz/yLu5+rw+MAaCKe9gNB1Rp+l/RHM3vVzLbWoyEAzVHr0/473f2Mmc2X9KKZve3u+8evkP1R2CpJS5YsqXF3AOqlpjO/u5/Jfg9Jek5S7wTr7HD3irtXOjs7a9kdgDqqOvxm1mFmX7t6W9I3Jb1Zr8YANFYtT/u7JD1nZlcf57/c/X/q0hWAhqs6/O5+QtI/1bGXa9aHH36YrI+Ojibr7733XrI+MjKSW8v+OOc6ffp0sn7x4sVkvUhbW1turb29vaZ97969O1l/4YUXcmtLly5Nbtvd3Z2s33///cn6VMBQHxAU4QeCIvxAUIQfCIrwA0ERfiCoenyrL7yTJ08m688880xNjz9z5sxkffbs2bm1jo6O5LbTppX3979oGHLdunXJ+ieffJKsP/7447m1hQsXJrctOm7Lli1L1qcCzvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/HVQdIWiG264IVm/dOlSPdupq/nz5yfrRV/LHR4ezq3NmJH+77dixYpkHbXhzA8ERfiBoAg/EBThB4Ii/EBQhB8IivADQTHOXwezZs1K1jdu3JisHz9+PFlfvHhxsn7w4MFkPWXOnDnJ+oYNG5L1orH6Dz74ILd29OjR5LZoLM78QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBU4Ti/me2U9G1JQ+6+Mls2V9LvJPVI6pd0n7ufb1ybU1vR99KXL1+erBddt//ChQu5tXfffTe57a233pqsF43jF0nNKdDb21vTY6M2kznz/0bS3V9Y9rCkfe5+s6R92X0AU0hh+N19v6SRLyzeJGlXdnuXpHvr3BeABqv2NX+Xuw9mt9+X1FWnfgA0Sc1v+Lm7S/K8upltNbM+M+tLXc8NQHNVG/6zZrZAkrLfQ3kruvsOd6+4e6XoQpcAmqfa8O+RtCW7vUXS8/VpB0CzFIbfzJ6V9H+S/tHMBszsAUmPStpgZsck3ZXdBzCFFA7iuvvmnNI36txLWEXj+EWKrp2fUnQtgZ6enqofG62NT/gBQRF+ICjCDwRF+IGgCD8QFOEHguLS3deASqWSW0t93VeShoZyP5wpSRoYGEjWiy4rjtbFmR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgmKc/xqQurz2mjVrktvu3bs3Wd+/f3+yvnDhwmS9qyv/8o5Flw1HY3HmB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgGOe/xs2aNStZX7t2bbL+0ksvJevHjh1L1vv7+3NrYzO95Vu6dGmy3tHRkawjjTM/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRVOM5vZjslfVvSkLuvzJZtl/R9ScPZao+4e/qL4WhJRdfdv+eee5L1l19+OVlPzQtw6NCh5LaDg4PJ+u23356sz549O1mPbjJn/t9IunuC5b9091XZD8EHppjC8Lv7fkkjTegFQBPV8pr/ITN7w8x2mtmcunUEoCmqDf+vJC2XtErSoKSf561oZlvNrM/M+oaHh/NWA9BkVYXf3c+6+6i7X5H0a0m9iXV3uHvF3SudnZ3V9gmgzqoKv5ktGHf3O5LerE87AJplMkN9z0paL2memQ1I+qmk9Wa2SpJL6pf0gwb2CKABCsPv7psnWPxUA3pBC5o7d26yftdddyXrp0+fzq298soryW1ff/31ZP3w4cPJ+rZt25L16PiEHxAU4QeCIvxAUIQfCIrwA0ERfiAoLt2NmrS3tyfry5cvz60dPHiwpn0fPXo0WT9w4EBu7Y477qhp39cCzvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBTj/EgaGUlfu/XEiRPJ+vnz53NrV65cqaqnqxYuXJis9/bmXmAK4swPhEX4gaAIPxAU4QeCIvxAUIQfCIrwA0Exzn+N++ijj5L1ou/Ev/3228n65cuXk/W2trbcWtG1AKZNS5+bbrzxxmTdzJL16DjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQheP8ZtYt6WlJXZJc0g53f8zM5kr6naQeSf2S7nP3/C9vo2oXL15M1t95553c2smTJ2t67KJx/FrcdNNNyXrRtfVTcwKg2GTO/J9J+rG7r5C0RtIPzWyFpIcl7XP3myXty+4DmCIKw+/ug+7+Wnb7Y0lHJC2StEnSrmy1XZLubVSTAOrvK73mN7MeSaslHZDU5e6DWel9jb0sADBFTDr8ZjZL0u8lbXP3z31g3N1dY+8HTLTdVjPrM7O+4eHhmpoFUD+TCr+ZtWks+L919z9ki8+a2YKsvkDS0ETbuvsOd6+4e6Wzs7MePQOog8Lw29hXo56SdMTdfzGutEfSluz2FknP1789AI0yma/0rpP0PUmHzexQtuwRSY9K+m8ze0DSKUn3NabFqe/ChQvJetHLoX379iXro6OjubWOjo7ktkVfmy0yf/78ZH316tW5tSVLltS0b9SmMPzu/mdJeV+M/kZ92wHQLHzCDwiK8ANBEX4gKMIPBEX4gaAIPxAUl+6epNQlsJ944onktkVj6ZcuXUrWZ86cmazPnj07WU8p+tTl2rVrk/Xu7u5kffr06V+5JzQHZ34gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCCrMOP+TTz6ZrPf19SXrAwMDubXrr78+ue0tt9ySrF933XXJepEZM/L/GVeuXJnc9rbbbkvWGae/dnHmB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgwozzP/jgg8n6okWLkvXU9el7enqq3lYqHmtva2tL1tesWZNba29vT26LuDjzA0ERfiAowg8ERfiBoAg/EBThB4Ii/EBQheP8ZtYt6WlJXZJc0g53f8zMtkv6vqSrk8s/4u57G9Vordy97BaAljKZD/l8JunH7v6amX1N0qtm9mJW+6W7/3vj2gPQKIXhd/dBSYPZ7Y/N7Iik9MfhALS8r/Sa38x6JK2WdCBb9JCZvWFmO81sTs42W82sz8z6hoeHJ1oFQAkmHX4zmyXp95K2uftHkn4labmkVRp7ZvDzibZz9x3uXnH3StG8cACaZ1LhN7M2jQX/t+7+B0ly97PuPuruVyT9WlJv49oEUG+F4Tczk/SUpCPu/otxyxeMW+07kt6sf3sAGmUy7/avk/Q9SYfN7FC27BFJm81slcaG//ol/aAhHQJoiMm82/9nSTZBqWXH9AEU4xN+QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoKyZl7Q2s2FJp8YtmifpXNMa+GpatbdW7Uuit2rVs7el7j6p6+U1Nfxf2rlZn7tXSmsgoVV7a9W+JHqrVlm98bQfCIrwA0GVHf4dJe8/pVV7a9W+JHqrVim9lfqaH0B5yj7zAyhJKeE3s7vN7K9mdtzMHi6jhzxm1m9mh83skJn1ldzLTjMbMrM3xy2ba2Yvmtmx7PeE06SV1Nt2MzuTHbtDZraxpN66zexPZvYXM3vLzH6ULS/12CX6KuW4Nf1pv5lNl3RU0gZJA5IOStrs7n9paiM5zKxfUsXdSx8TNrN/lnRB0tPuvjJb9jNJI+7+aPaHc467/1uL9LZd0oWyZ27OJpRZMH5maUn3SvpXlXjsEn3dpxKOWxln/l5Jx939hLv/TdJuSZtK6KPluft+SSNfWLxJ0q7s9i6N/edpupzeWoK7D7r7a9ntjyVdnVm61GOX6KsUZYR/kaTT4+4PqLWm/HZJfzSzV81sa9nNTKArmzZdkt6X1FVmMxMonLm5mb4ws3TLHLtqZryuN97w+7I73f3rkr4l6YfZ09uW5GOv2VppuGZSMzc3ywQzS/9dmceu2hmv662M8J+R1D3u/uJsWUtw9zPZ7yFJz6n1Zh8+e3WS1Oz3UMn9/F0rzdw80czSaoFj10ozXpcR/oOSbjazZWbWLum7kvaU0MeXmFlH9kaMzKxD0jfVerMP75G0Jbu9RdLzJfbyOa0yc3PezNIq+di13IzX7t70H0kbNfaO/zuSflJGDzl9/YOk17Oft8ruTdKzGnsa+KnG3ht5QNJNkvZJOibpJUlzW6i3ZyQdlvSGxoK2oKTe7tTYU/o3JB3KfjaWfewSfZVy3PiEHxAUb/gBQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwjq/wFPK1OkXgT91QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0],cmap=plt.cm.binary)\n",
    "print (x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 34us/step\n"
     ]
    }
   ],
   "source": [
    "val_loss,val_acc=model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.09658897189488634, 0.9698)\n"
     ]
    }
   ],
   "source": [
    "print(val_loss,val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "`save_model` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-7b7b789f82a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epic_num_reader.model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/network.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msave_model\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m     \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/engine/saving.pyc\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`save_model` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: `save_model` requires h5py."
     ]
    }
   ],
   "source": [
    "model.save('epic_num_reader.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
